# 文档简介：《深度学习入门》

**基本信息**
- **标题**：深度学习入门
- **作者**：咩咩宇
- **时间**：2025年9月

**核心内容摘要**

这份文档详细梳理了深度学习的基础理论与经典模型，主要包含以下五个部分：

### 1. 线性回归与优化基础
- 详细讲解了线性回归模型的定义、误差函数（均方误差）的计算。
- 推导了最小二乘法的向量形式求解过程，并介绍了梯度下降法的原理与参数更新公式。

### 2. 逻辑回归与模型评估
- 阐述了逻辑回归算法原理，包括 Sigmoid 函数及其求导、交叉熵损失函数的推导。
- 系统总结了分类模型评价指标（准确率、精确率、召回率、F1值）与回归模型评价指标（MAE、MSE、RMSE 等）。
- 解释了训练集、验证集与测试集的划分及其在模型优化中的作用。

### 3. 全连接神经网络 (MLP)
- 展示了全连接神经网络的整体架构与结构单元。
- 深入分析了激活函数的作用，并对比了常见激活函数（Sigmoid、Tanh、ReLU、Leaky ReLU、SoftMax）的公式、优缺点及导数图像。
- 简述了前向传播与反向传播的基本概念。

### 4. 卷积神经网络 (CNN)
- 介绍了 CNN 处理网格结构数据（如图像）的核心优势及基本结构（卷积层、池化层、全连接层）。
- 详解了卷积运算的细节，包括卷积核、步长 (Stride)、填充 (Padding) 以及多通道运算机制。
- 列举了经典模型（如 LeNet-5, AlexNet, ResNet 等）及其应用场景。

### 5. 循环神经网络 (RNN) 与 LSTM
- 讲解了 RNN 处理序列数据的结构特点（折叠视角与展开视角）及其数学模型。
- 分析了 RNN 中的梯度爆炸与梯度消失问题及其成因（BPTT 中的矩阵连乘）。
- 重点解析了长短期记忆网络 (LSTM) 的架构，详细推导了遗忘门、输入门、输出门及细胞状态更新的数学过程，并解释了 LSTM 如何缓解梯度消失问题。
